---
layout: page
title: Resources
---

Recommended reading and other resources for safety risk management.

## Original recommendations

* [How Complex Systems Fail](http://web.mit.edu/2.75/resources/random/How%20Complex%20Systems%20Fail.pdf) - a short introduction by Richard Cook applying systems thinking to safety
* [How Complex Systems Fail, Velocity 2012](https://www.youtube.com/watch?v=2S0k12uZR14) - a talk by Richard Cook relating systems safety to IT
* [Engineering a Safer World](https://mitpress.mit.edu/books/engineering-safer-world) - a free MIT book introducing STAMP (Systems-Theoretic Accident Modeling and Processes) and STPA (STAMP-Based Process Analysis)
* [MIT Partnership for a Systems Approach to Safety (PSAS)](https://psas.scripts.mit.edu/home/)

## Short essays
* [Resilience Engineering](https://erikhollnagel.com/ideas/resilience-engineering.html) - Erik Hollnagel's account of the origins of Resilience Engineering
* [Resilience Assessment Grid](https://erikhollnagel.com/ideas/resilience%20assessment%20grid.html) - recommended for the succinct description of the four potentials of resilient performance in the beginning of the essay: Respond, Monitor, Learn, Anticipate
* [The NO view of 'human error'](https://erikhollnagel.com/ideas/no-view-of-human-error.html) - argues that we should stop using 'human error' as an explanation for accidents/failures as it is not helpful

## Introductory books

* [Normal Accidents: Living with High-Risk Technologies](https://en.wikipedia.org/wiki/Normal_Accidents) - an older but influential book written by Charles Perrow, a sociologist, in the aftermath of the [Three Mile Island accident](https://en.wikipedia.org/wiki/Three_Mile_Island_accident) - Perrow's ideas of coupling and complexity are still valid today
* [The Field Guide to Understanding 'Human Error'](https://www.routledge.com/The-Field-Guide-to-Understanding-Human-Error-3rd-Edition/Dekker/p/book/9781472439055) by [Sidney Dekker](https://sidneydekker.com) - recommended by several people as an easily understandable introduction to resilience engineering concepts from safety, also available on [Oâ€™Reilly](https://www.oreilly.com/library/view/the-field-guide/9781317031833/)
* *[Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations](https://itrevolution.com/book/accelerate/)* - [Nicole Forsgren](https://nicolefv.com), Jez Humble, Gene Kim - primarily a DevOps book, with some safety influences, namely Westrum's concept of [*generative culture*](https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture), describes both the methodology and results of research led by Dr. Nicole Forsgren

## Notable academic papers
* Bainbridge, L. (1983). IRONIES OF AUTOMATION. [IRONIES OF AUTOMATION](https://www.sciencedirect.com/science/article/pii/B9780080293486500269?via%3Dihub), [PDF](https://www.ise.ncsu.edu/wp-content/uploads/2017/02/Bainbridge_1983_Automatica.pdf) - a classic and accessible paper on the downside of automation that stands up even today
* Endsley, M. R. (1995). [Toward a Theory of Situation Awareness in Dynamic Systems](https://journals.sagepub.com/doi/10.1518/001872095779049543), [PDF](https://www.researchgate.net/profile/Mica_Endsley/publication/210198492_Endsley_MR_Toward_a_Theory_of_Situation_Awareness_in_Dynamic_Systems_Human_Factors_Journal_371_32-64/links/548f61bf0cf214269f263b08.pdf) - Endsley's main paper on [Situation Awareness](https://en.wikipedia.org/wiki/Situation_awareness), a theoretical construct that is useful in understanding decisions made by operators in emergency situations
* Helmreich, R. L., Klinect, J. R., & Wilhelm, J. A. (1999). Models of threat, error, and CRM in flight operations, [PDF](https://www.flightsafety.org/files/models_of_threat_error.pdf) - an excellent paper covering key aspects of modern aviation safety: Crew Resource Management, the Line Operations Safety Audit, and Threat and Error Management
* Garvin, D. A., Edmondson, A. C., & Gino, F. (2008). Is yours a learning organization, [PDF](https://www.researchgate.net/profile/Amy_Edmondson/publication/5440662_Is_Yours_a_Learning_Organization/links/0fcfd5057191e297d0000000/Is-Yours-a-Learning-Organization.pdf) - a solid methodology for assessing the depth of learning within your organization, with links to self-assessments
* Aven, T., Renn, O., & Rosa, E. A. (2011). [On the ontological status of the concept of risk](https://www.sciencedirect.com/science/article/pii/S0925753511000981?via%3Dihub), [PDF](https://www.academia.edu/34623476/On_the_ontological_status_of_the_concept_of_risk) - Aven's career has been to establish safety as a science; this article strives to define what risk actually is
* Hollnagel, E., Wears, R. L., & Braithwaite, J. (2015). From Safety-I to Safety-II: a white paper, [PDF](https://www.england.nhs.uk/signuptosafety/wp-content/uploads/sites/16/2015/10/safety-1-safety-2-whte-papr.pdf) - an evolution of Hollnagel's concept of Resilience Engineering, making the case that safety should focus not just on accidents (when things go unexpectedly poorly), but the full range of outcomes
* Dekker, S. W. A. (2017). [Rasmussen's legacy and the long arm of rational choice](https://www.sciencedirect.com/science/article/abs/pii/S0003687016300254?via%3Dihub), [PDF](http://sidneydekker.com/wp-content/uploads/2017/09/RasmussenLongArm.pdf) - the paper explores the moral aspects behind our tendency to blame people for causing accidents, and how blame can be harmful

## Graduate Degree Programs
Three programs with graduates active in the IT Resilience Engineering community:
* [Human Factors & System Safety](http://www.humanfactors.lth.se) at Lund University, Sweden - this is where John Allspaw ([thesis](https://lup.lub.lu.se/student-papers/search/publication/8084520)) and others active in the [learning from incidents](https://www.learningfromincidents.io) community have pursued their degrees, including J Paul Reed ([thesis](https://lup.lub.lu.se/student-papers/search/publication/8966930)) - 1 or 2 year program, with mandatory on-site learning labs.
* [Cognitive Systems Engineering](https://ise.osu.edu/faculty-research/cognitive-systems-engineering) at *The* Ohio State University - David Woods is on faculty, and Laura Maguire completed her PhD here ([talk based on her work](https://www.infoq.com/presentations/incident-command-system/))
* [Managing Risk and System Change](https://psychology.tcd.ie/postgraduate/msc-riskandchange/) at Trinity College Dublin, Ireland - I am currently pursuing my MSc in Psychology here, and will post my thesis when it's done! 2 year masters program, all online. A broader curriculum than Human Factors & Systems Safety, covering: human factors and sociotechnical systems safety, organizational change, safety risk assessment and risk management, design, organizational psychology and leadership, human resources, statistics, and research methodology.

## Organizations
* [Resilience Engineering Association](https://www.resilience-engineering-association.org): *the official home of Resilience Engineering* "Resilience Engineering is a trans-disciplinary perspective that focuses on developing on theories and practices that are necessary to enable complex-socio technical systems and organizations to continue operations or to deliver essential services when dealing with expected and unexpected situations (prior, during and after). It addesses complexity, non-linearity, inter-dependencies, emergence, formal and informal social structures, threats and opportunities."
* [Society for Risk Analysis](https://www.sra.org) (SRA): "The Society for Risk Analysis is a multidisciplinary, interdisciplinary, scholarly, international society that provides an open forum for all those who are interested in risk analysis. Risk analysis is broadly defined to include risk assessment, risk characterization, risk communication, risk management, and policy relating to risk, in the context of risks of concern to individuals, to public- and private-sector organizations, and to society at a local, regional, national, or global level."
* [Society of Information Risk Analysts](https://www.societyinforisk.org) (SIRA): *Data > Dogma* "The Society of Information Risk Analysts (SIRA), established in 2011, is the go-to resource for decision makers & practitioners of information risk management. We endeavor to do this by supporting the collaborative efforts of our members through research, knowledge sharing, and member-driven education."

## Other curated lists
* [@dastergon](https://dastergon.gr)'s [Awesome Chaos Engineering](https://github.com/dastergon/awesome-chaos-engineering)
* [@dastergon](https://dastergon.gr)'s [Awesome Site Reliability Engineering](https://github.com/dastergon/awesome-sre)
* [@lorin](http://lorinhochstein.org)'s [Resilience engineering papers](https://github.com/lorin/resilience-engineering)
* [@lorin](http://lorinhochstein.org)'s [Cognitive Systems Engineering](https://github.com/lorin/cognitive-systems-engineering)
