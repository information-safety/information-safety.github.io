---
layout: page
title: Resources
---

Recommended reading and other resources for safety risk management.

## Original recommendations

* [How Complex Systems Fail](https://how.complexsystems.fail), [PDF](https://web.archive.org/web/20200709194039/http://web.mit.edu/2.75/resources/random/How%20Complex%20Systems%20Fail.pdf) - a short introduction by Richard Cook applying systems thinking to safety
* [How Complex Systems Fail, Velocity 2012](https://www.youtube.com/watch?v=2S0k12uZR14) - a talk by Richard Cook relating systems safety to IT
* [Engineering a Safer World](https://mitpress.mit.edu/books/engineering-safer-world) - a free MIT book introducing STAMP (Systems-Theoretic Accident Modeling and Processes) and STPA (STAMP-Based Process Analysis)
* [MIT Partnership for a Systems Approach to Safety (PSAS)](https://psas.scripts.mit.edu/home/)

## Short essays

* [Resilience Engineering](https://erikhollnagel.com/ideas/resilience-engineering.html) - Erik Hollnagel's account of the origins of Resilience Engineering
* [Resilience Assessment Grid](https://erikhollnagel.com/ideas/resilience%20assessment%20grid.html) - recommended for the succinct description of the four potentials of resilient performance in the beginning of the essay: Respond, Monitor, Learn, Anticipate
* [The NO view of 'human error'](https://erikhollnagel.com/ideas/no-view-of-human-error.html) - argues that we should stop using 'human error' as an explanation for accidents/failures as it is not helpful
* [From the coalface: an essay on the early history of sociotechnical systems](https://eight2late.wordpress.com/2015/04/07/from-the-coalface-an-essay-on-the-early-history-of-sociotechnical-systems/) - a blog post on how the idea of sociotechnical systems came from the study of coal mining in Britain and the insight that the "*best work arrangements come out of seeking a match between technical and social elements of the modern day workplace*"

## Books

* [Normal Accidents: Living with High-Risk Technologies](https://en.wikipedia.org/wiki/Normal_Accidents) - an older but influential book written by Charles Perrow, a sociologist, in the aftermath of the [Three Mile Island accident](https://en.wikipedia.org/wiki/Three_Mile_Island_accident) - Perrow's ideas of coupling and complexity are still valid today
* [The Field Guide to Understanding 'Human Error'](https://www.routledge.com/The-Field-Guide-to-Understanding-Human-Error-3rd-Edition/Dekker/p/book/9781472439055) by [Sidney Dekker](https://sidneydekker.com) - recommended by several people as an easily understandable introduction to resilience engineering concepts from safety, also available on [O’Reilly](https://www.oreilly.com/library/view/the-field-guide/9781317031833/)
* *[Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations](https://itrevolution.com/book/accelerate/)* - [Nicole Forsgren](https://nicolefv.com), Jez Humble, Gene Kim - primarily a DevOps book, with some safety influences, namely Westrum's concept of [*generative culture*](https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture), describes both the methodology and results of research led by Dr. Nicole Forsgren

## Notable academic papers

* Bainbridge, L. (1983). IRONIES OF AUTOMATION. [IRONIES OF AUTOMATION](https://www.sciencedirect.com/science/article/pii/B9780080293486500269?via%3Dihub), [PDF](https://ckrybus.com/static/papers/Bainbridge_1983_Automatica.pdf) - a classic and accessible paper on the downside of automation that stands up even today
* Endsley, M. R. (1995). [Toward a Theory of Situation Awareness in Dynamic Systems](https://journals.sagepub.com/doi/10.1518/001872095779049543), [PDF](https://www.researchgate.net/profile/Mica_Endsley/publication/210198492_Endsley_MR_Toward_a_Theory_of_Situation_Awareness_in_Dynamic_Systems_Human_Factors_Journal_371_32-64/links/548f61bf0cf214269f263b08.pdf) - Endsley's main paper on [Situation Awareness](https://en.wikipedia.org/wiki/Situation_awareness), a theoretical construct that is useful in understanding decisions made by operators in emergency situations
* Helmreich, R. L., Klinect, J. R., & Wilhelm, J. A. (1999). Models of threat, error, and CRM in flight operations, [PDF](https://www.flightsafety.org/files/models_of_threat_error.pdf) - an excellent paper covering key aspects of modern aviation safety: Crew Resource Management, the Line Operations Safety Audit, and Threat and Error Management
* Garvin, D. A., Edmondson, A. C., & Gino, F. (2008). Is yours a learning organization, [PDF](https://www.researchgate.net/profile/Amy_Edmondson/publication/5440662_Is_Yours_a_Learning_Organization/links/0fcfd5057191e297d0000000/Is-Yours-a-Learning-Organization.pdf) - a solid methodology for assessing the depth of learning within your organization, with links to self-assessments
* Aven, T., Renn, O., & Rosa, E. A. (2011). [On the ontological status of the concept of risk](https://www.sciencedirect.com/science/article/pii/S0925753511000981?via%3Dihub), [PDF](https://www.academia.edu/34623476/On_the_ontological_status_of_the_concept_of_risk) - Aven's career has been to establish safety as a science; this article strives to define what risk actually is
* Hollnagel, E., Wears, R. L., & Braithwaite, J. (2015). From Safety-I to Safety-II: a white paper, [PDF](https://www.england.nhs.uk/signuptosafety/wp-content/uploads/sites/16/2015/10/safety-1-safety-2-whte-papr.pdf) - an evolution of Hollnagel's concept of Resilience Engineering, making the case that safety should focus not just on accidents (when things go unexpectedly poorly), but the full range of outcomes
* Hollnagel, E. (2014). [Is safety a subject for science?](https://doi.org/10.1016/j.ssci.2013.07.025), [PDF](https://www.academia.edu/22733547/Is_safety_a_subject_for_science) - an earlier paper by Hollnagel that introduces Safety-II by arguing that we can’t have a science based on the non-occurrence of events (accidents)
* Dekker, S. W. A. (2017). [Rasmussen's legacy and the long arm of rational choice](https://www.sciencedirect.com/science/article/abs/pii/S0003687016300254?via%3Dihub), [PDF](https://sidneydekker.com/wp-content/uploads/2017/09/RasmussenLongArm.pdf) - the paper explores the moral aspects behind our tendency to blame people for causing accidents, and how blame can be harmful
* Repenning, N. P., & Sterman, J. D. (2001). [Nobody Ever Gets Credit for Fixing Problems that Never Happened: CREATING AND SUSTAINING PROCESS IMPROVEMENT](https://doi.org/10.2307/41166101), [PDF](http://scripts.mit.edu/~jsterman/docs/Repenning-2001-NobodyEverGetsCredit.pdf) - an analysis of a challenge that faces many risk programs: why process improvement programs fail and succeed
* Rae, A., Provan, D., Aboelssaad, H., & Alexander, R. (2020). [A manifesto for Reality-based Safety Science](https://doi.org/10.1016/j.ssci.2020.104654), [PDF](https://www.researchgate.net/profile/Andrew_Rae/publication/339289702_A_manifesto_for_Reality-based_Safety_Science/links/5e755d6d4585157b9a4da1dc/A-manifesto-for-Reality-based-Safety-Science.pdf) - a call for development of theories that can be empirically tested and are useful to practitioners, including a list of commitments for future research
* Provan, D. J., Woods, D. D., Dekker, S. W. A., & Rae, A. J. (2020). [Safety II professionals: How resilience engineering can transform safety practice](https://doi.org/10.1016/j.ress.2019.106740), [PDF](https://research-repository.griffith.edu.au/bitstream/handle/10072/389308/Provan268657-Published.pdf?sequence=5) - a proposal for changing safety programs to adopt principles of Safety-II (also applicable to information risk management)

## Other Media

Videos, podcasts and other media.

* [The Safety of Work](https://safetyofwork.com) - a now biweekly podcast where Drew Rae and David Provan, two safety practitioners and researchers, review academic research and discuss the implications for safety management
* [The Key to High Performance: What the Data Says](https://www.youtube.com/watch?v=RBuPlMTXuFc&t=25s) - Nicole Forgren presents results of her research at DevOps Enterprise Summit San Francisco 2017
* [2019 Accelerate State of DevOps Report](https://research.google/pubs/pub48455/) - the latest (and likely last) State of DevOps Report produced under the direction of Nicole Forsgren
* The [STPA Handbook](https://psas.scripts.mit.edu/home/materials/) - a whitepaper written by Nancy Leveson and John Thomas to help practitioners learn to use STPA

## Graduate Degree Programs

Three programs with graduates active in the IT Resilience Engineering community:

* [Human Factors & System Safety](https://www.humanfactors.lth.se) at Lund University, Sweden - this is where John Allspaw ([thesis](https://lup.lub.lu.se/student-papers/search/publication/8084520)) and others active in the [learning from incidents](https://www.learningfromincidents.io) community have pursued their degrees, including J Paul Reed ([thesis](https://lup.lub.lu.se/student-papers/search/publication/8966930)) - 1 or 2 year program, with mandatory on-site learning labs.
* [Cognitive Systems Engineering](https://ise.osu.edu/faculty-research/cognitive-systems-engineering) at *The* Ohio State University - David Woods is on faculty, and Laura Maguire completed her PhD here ([talk based on her work](https://www.infoq.com/presentations/incident-command-system/))
* [Managing Risk and System Change](https://psychology.tcd.ie/postgraduate/msc-riskandchange/) at Trinity College Dublin, Ireland - I am currently pursuing my MSc in Psychology here, and will post my thesis when it's done! 2 year masters program, all online. A broader curriculum than Human Factors & Systems Safety, covering: human factors and sociotechnical systems safety, organizational change, safety risk assessment and risk management, design, organizational psychology and leadership, human resources, statistics, and research methodology.

## Organizations

* [Resilience Engineering Association](https://www.resilience-engineering-association.org): *the official home of Resilience Engineering* "Resilience Engineering is a trans-disciplinary perspective that focuses on developing on theories and practices that are necessary to enable complex-socio technical systems and organizations to continue operations or to deliver essential services when dealing with expected and unexpected situations (prior, during and after). It addesses complexity, non-linearity, inter-dependencies, emergence, formal and informal social structures, threats and opportunities."
* [Society for Risk Analysis](https://www.sra.org) (SRA): "The Society for Risk Analysis is a multidisciplinary, interdisciplinary, scholarly, international society that provides an open forum for all those who are interested in risk analysis. Risk analysis is broadly defined to include risk assessment, risk characterization, risk communication, risk management, and policy relating to risk, in the context of risks of concern to individuals, to public- and private-sector organizations, and to society at a local, regional, national, or global level."
* [Society of Information Risk Analysts](https://www.societyinforisk.org) (SIRA): *Data > Dogma* "The Society of Information Risk Analysts (SIRA), established in 2011, is the go-to resource for decision makers & practitioners of information risk management. We endeavor to do this by supporting the collaborative efforts of our members through research, knowledge sharing, and member-driven education."

## Other curated lists

* [@dastergon](https://dastergon.gr)'s [Awesome Chaos Engineering](https://github.com/dastergon/awesome-chaos-engineering)
* [@dastergon](https://dastergon.gr)'s [Awesome Site Reliability Engineering](https://github.com/dastergon/awesome-sre)
* [@lorin](http://lorinhochstein.org)'s [Resilience engineering papers](https://github.com/lorin/resilience-engineering)
* [@lorin](http://lorinhochstein.org)'s [Cognitive Systems Engineering](https://github.com/lorin/cognitive-systems-engineering)
